{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "plt.rcParams['figure.figsize'] = [12,6]\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our data consist of 31 columns.\n",
    "* All are numerical variables.\n",
    "* There is no missing values.\n",
    "* Our dependent variable is 'Class' and the rest are independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just the 'Time' columns since we cannot do anything with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Time',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all variables are unknown and it is hard to do analysis because we do not know what each column represents to. So, I'll just skip the exploratory data analysis part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24971047bc8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can clearly see that this is an imbalanced dataset. We have like 0.0017% fraud transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the evaluation metric\n",
    "Our objective is to detect all fraud transactions (true positive). we need to make sure that no fraud transactions are being classified as non-fraud (false negative) and no non-fraud transactions are being classified as fraud (false positive). So, we need to keep this false negative and false positive as low as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Recall = \\frac{True Positive}{True Positive + False Negative}\n",
    "$$\n",
    "\n",
    "High recall score indicates low false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Precision = \\frac{True Positive}{True Positive + False Positive}\n",
    "$$\n",
    "\n",
    "High precision score indicates low false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "F1 = 2 \\frac {Precision * Recall}{Precision + Recall}\n",
    "$$\n",
    "\n",
    "We can also use F1-score, a metric that conveys both precision score and recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Class\",axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling/Normalization\n",
    "Next, we will do scaling on our data because we will be using distance-based algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=5000)\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC()\n",
    "tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "lgbm = LGBMClassifier(is_unbalanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(lr,'Logistic Regression'), (knn,'K-Nearest Neighbors'), (svm,'Support Vector Classifier'),\n",
    "          (tree,'Decision Tree Classifier'), (forest,'Random Forest Classifier'),\n",
    "         (lgbm,'LightGBM Classifier')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Computational Time (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.709924</td>\n",
       "      <td>2.062899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.819788</td>\n",
       "      <td>686.037193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classifier</th>\n",
       "      <td>0.759690</td>\n",
       "      <td>338.932644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>12.093573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.845070</td>\n",
       "      <td>180.245673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM Classifier</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.141009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           F1-score  Computational Time (seconds)\n",
       "Logistic Regression        0.709924                      2.062899\n",
       "K-Nearest Neighbors        0.819788                    686.037193\n",
       "Support Vector Classifier  0.759690                    338.932644\n",
       "Decision Tree Classifier   0.760000                     12.093573\n",
       "Random Forest Classifier   0.845070                    180.245673\n",
       "LightGBM Classifier        0.333333                      3.141009"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "model_name = []\n",
    "training_time = []\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # training\n",
    "    model[0].fit(X_train_scaled,y_train)\n",
    "    \n",
    "    # prediction\n",
    "    prediction = model[0].predict(X_test_scaled)\n",
    "    \n",
    "    # evaluation\n",
    "    score = f1_score(y_test,prediction)\n",
    "    scores.append(score)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    # computational time\n",
    "    difference = end - start\n",
    "    training_time.append(difference)\n",
    "    \n",
    "    # model_name\n",
    "    model_name.append(model[1])\n",
    "\n",
    "data = []\n",
    "for x in (zip(scores,training_time)):\n",
    "    data.append(x)\n",
    "    \n",
    "model_df = pd.DataFrame(data,index=model_name,columns=['F1-score','Computational Time (seconds)'])\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forest scores the best followed by K-Nearest Neighbors.\n",
    "* But look at their computational time. Random Forest performed 74% faster compare to K-Nearest Neighbors.\n",
    "* LightGBM performed the worst, but maybe we can improve this model by tuning the hyperparameters.\n",
    "* We'll choose LightGBM for the hyperparameter tuning part. Less computational time means it is easier for us to find the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 10,\n",
       " 'n_estimators': 1500,\n",
       " 'n_jobs': -1,\n",
       " 'objective': 'binary',\n",
       " 'reg_alpha': 1,\n",
       " 'reg_lambda': 1}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {}\n",
    "param['n_estimators'] = [1000,1500]\n",
    "param['max_depth'] = [10,15]\n",
    "param['learning_rate'] = [0.01,0.1]\n",
    "param['objective'] = ['binary']\n",
    "param['reg_lambda'] = [1,2]\n",
    "param['reg_alpha'] = [1,2]\n",
    "param['n_jobs'] = [-1]\n",
    "param['colsample_bytree'] = [0.2,0.5]\n",
    "\n",
    "grid = GridSearchCV(lgbm, param, n_jobs=-1, scoring='f1')\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421052631578948"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = grid.predict(X_test_scaled)\n",
    "score = f1_score(y_test,prediction)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we manage to increase the F1-score from 33.3% to 84.2%. That is such a huge improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
