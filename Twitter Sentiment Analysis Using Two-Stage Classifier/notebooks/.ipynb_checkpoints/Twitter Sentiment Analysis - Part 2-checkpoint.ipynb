{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421216da",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "listed-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "plt.rcParams['figure.figsize'] = 12,6\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold, StratifiedKFold\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ccca3",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b938394f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>tweet</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.3818</td>\n",
       "      <td>aww that bummer you shoulda get david carr of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.7269</td>\n",
       "      <td>be upset that he can update his facebook by te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4939</td>\n",
       "      <td>dive many time for the ball manage to save the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.2500</td>\n",
       "      <td>my whole body feel itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.6597</td>\n",
       "      <td>no it not behave at all mad why be here becaus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compound                                              tweet  polarity\n",
       "0   -0.3818  aww that bummer you shoulda get david carr of ...         0\n",
       "1   -0.7269  be upset that he can update his facebook by te...         0\n",
       "2    0.4939  dive many time for the ball manage to save the...         0\n",
       "3   -0.2500      my whole body feel itchy and like its on fire         0\n",
       "4   -0.6597  no it not behave at all mad why be here becaus...         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_lemma.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b4f034",
   "metadata": {},
   "source": [
    "## A little bit data cleaning\n",
    "Lexicon scores that are above 0 are considered as positive, and negative if they are below 0. We should expect to get positive lexicon for positive tweets and negative lexicon for negative tweets. But I noticed that many tweets do not behave like this. Maybe there is error during labelling process, or maybe the tweets contain sarcasm element that our VADER lexicon could not understand it. So we will just ignore all these tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a35ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df[df['polarity']==1].copy()\n",
    "df_neg = df[df['polarity']==0].copy()\n",
    "\n",
    "df_pos = df_pos[df_pos['compound'] > 0]\n",
    "df_neg = df_neg[df_neg['compound'] < 0]\n",
    "\n",
    "df = pd.concat([df_pos,df_neg], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e024b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ad19b",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a04defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tweet']\n",
    "y = df['polarity']\n",
    "\n",
    "# return score - for svc\n",
    "def evaluate_model(model, X, y, metrics='accuracy'):\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range=(1, 3), max_df=0.5, min_df=2)\n",
    "    pipeline = Pipeline(steps=[('tfidf',tfidf),('model',model)])\n",
    "    cv = KFold(10,shuffle=True,random_state=123)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring=metrics)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# return probability\n",
    "def evaluate_proba(model, X, y):\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range=(1, 3), max_df=0.5, min_df=2)\n",
    "    pipeline = Pipeline(steps=[('tfidf',tfidf),('model',model)])\n",
    "    cv = KFold(10,shuffle=True,random_state=123)\n",
    "    proba = cross_val_predict(pipeline, X, y, cv=cv, method='predict_proba')\n",
    "    \n",
    "    return proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a322305",
   "metadata": {},
   "source": [
    "## First stage - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae17210",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = ComplementNB()\n",
    "first_proba = evaluate_proba(model_1, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48bd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.where(np.logical_and(first_proba[:,1] > first_proba[:,0], first_proba[:,1] < 0.95))[0].tolist()\n",
    "b = np.where(np.logical_and(first_proba[:,0] > first_proba[:,1], first_proba[:,0] < 0.95))[0].tolist()\n",
    "\n",
    "a.extend(b)\n",
    "a = np.array(a)\n",
    "a = a.tolist()\n",
    "\n",
    "first_success = np.delete(first_proba, a, 0)\n",
    "y_success = np.delete(np.array(y),a)\n",
    "first_success = np.where(first_success[:,1] > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2333c4",
   "metadata": {},
   "source": [
    "We set 0.95 as our threshold. Any data points with probability less than this threshold will be forwarded to the second stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e57b88",
   "metadata": {},
   "source": [
    "## Second stage - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23e7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = LinearSVC(random_state=123,\n",
    "                    penalty='l1',\n",
    "                    dual=False,\n",
    "                    C=0.45)\n",
    "\n",
    "second_score = evaluate_model(model_2, X[a], y[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e6c6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 97.473 %\n"
     ]
    }
   ],
   "source": [
    "h, i = np.diag(confusion_matrix(y_success,first_success))\n",
    "second_score_mean = np.mean(second_score) * len(X[a])\n",
    "\n",
    "overall_score = (h + i + second_score_mean) / len(df)\n",
    "print(f'Accuracy score: {overall_score*100:.3f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572fe217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
